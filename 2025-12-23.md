# LSTM 기반 DeepSurv 모델 고도화 작업 로그

**날짜**: 2025년 12월 23일  
**담당**: ESS DeepSurv Research Team  
**프로젝트**: Battery ESS RUL Prediction using Survival Analysis

---

## 1. 작업 요약 (Executive Summary)

기존 정적(Static) 데이터 기반의 DeepSurv 모델(`DeepSurv_Journal_Analysis.py`)은 배터리의 단일 시점 스냅샷만을 활용하여 RUL(Remaining Useful Life)을 예측하는 한계가 있었습니다. 이를 극복하기 위해 **시계열 특성을 반영**할 수 있는 **LSTM(Long Short-Term Memory) 아키텍처**와 **Sliding Window 기반 데이터 파이프라인**을 새롭게 구축하였습니다.

본 고도화 작업은 다음과 같은 핵심 개선을 달성하였습니다:

- **시퀀스 학습 가능**: 배터리 열화의 시간적 패턴(추세, 가속도)을 모델이 자동으로 학습
- **동적 특징 추출**: LSTM이 연속된 사이클의 의존성(Temporal Dependency)을 포착
- **자동 하이퍼파라미터 최적화**: Optuna를 통한 체계적인 성능 탐색
- **모듈화된 코드 구조**: 유지보수성과 확장성 향상

---

## 2. 기술적 비교 (Technical Comparison)

### 2.1 아키텍처 및 데이터 처리 비교표

| **구분**                 | **Baseline (기존 모델)**                                  | **Advanced (LSTM 기반 모델)**                                   |
|-------------------------|--------------------------------------------------------|--------------------------------------------------------------|
| **데이터 처리 방식**        | 단일 시점 스냅샷 (Single Snapshot)                          | Sliding Window (Window Size = 10)                             |
| **입력 형태**             | 2D Tensor: (Batch, Features)                          | 3D Tensor: (Batch, Window, Features)                         |
| **특징 공학**             | 수동 Feature Engineering<br>(이동 평균, 표준편차, 미분값 등 사전 계산) | LSTM이 시계열 패턴을 자동 학습<br>(가속화 구간, 추세 변화 등)                  |
| **모델 구조**             | MLP (Multi-Layer Perceptron)<br>Fully Connected Layers | LSTM (Temporal Feature Extraction)<br>+ MLP Head             |
| **레이어 구성**            | Linear → ReLU → BatchNorm → Dropout<br>(3~4 Layers)   | LSTM(2 Layers) → Last Step → Linear(2 Layers)                |
| **학습 대상**             | 정적 상태 변수<br>(capacity, soh, derivatives)            | 동적 시퀀스 패턴<br>(시간에 따른 상태 변화 및 상호작용)                         |
| **하이퍼파라미터 최적화**    | 고정된 값<br>(hidden_layers=[64, 32, 16], lr=1e-3)       | Optuna 자동 탐색<br>(window_size, hidden_dim, num_layers, lr 등) |
| **코드 구조**             | Monolithic<br>(단일 파일 2547 lines)                      | Modular<br>(data_loader, models, trainer, optuna_search 분리)  |
| **재현성 및 확장성**        | 낮음<br>(코드 수정 시 전체 재실행 필요)                           | 높음<br>(모듈별 독립 실행 및 테스트 가능)                                  |

### 2.2 손실 함수 및 평가 지표

| **항목**          | **Baseline**            | **Advanced**            |
|------------------|------------------------|------------------------|
| 손실 함수          | Cox Proportional Hazards Loss | Cox Proportional Hazards Loss (동일) |
| 평가 지표          | C-Index, Brier Score, IBS | C-Index (핵심 지표로 단순화)    |
| 조기 종료 (Early Stopping) | Patience=30 (고정) | Patience=20 (동적 조정 가능) |

---

## 3. 모듈별 구현 내용 (Module-wise Implementation)

### 3.1 `src/data_loader.py` - 데이터 처리 및 시퀀스 변환

#### **핵심 기능**:
1. **Sliding Window 데이터셋 생성**:
   - 각 배터리의 연속된 N개 사이클(Window Size)을 하나의 샘플로 변환
   - 입력: `(Window_Size, Features)` → 출력: `(Batch, Window, Features)`
   
2. **전처리 로직 계승**:
   - 기존 `DeepSurv_Journal_Analysis.py`의 이상치 제거 및 스무딩 로직 유지
   - Median Filter 적용으로 측정 노이즈 제거

3. **PyTorch Dataset 구현**:
   ```python
   class BatteryDataset(Dataset):
       def __init__(self, features, times, events):
           self.features = features  # (N, Window, Features)
           self.times = times        # (N,) RUL at window end
           self.events = events      # (N,) Event indicator
   ```

#### **코드 예시**:
```python
def create_sequences(self, battery_df, window_size=10):
    """배터리 데이터를 시계열 시퀀스로 변환"""
    features, times, events = [], [], []
    
    for i in range(len(battery_df) - window_size):
        # Window: [i, i+1, ..., i+window_size-1]
        window_data = battery_df.iloc[i:i+window_size][feature_columns]
        target_time = battery_df.iloc[i+window_size]['time_to_eol']
        target_event = battery_df.iloc[i+window_size]['event']
        
        features.append(window_data.values)
        times.append(target_time)
        events.append(target_event)
    
    return np.array(features), np.array(times), np.array(events)
```

---

### 3.2 `src/models.py` - LSTM-DeepSurv 아키텍처

#### **모델 구조**:
```
Input (Batch, Window=10, Features)
    ↓
LSTM Layer(s) (num_layers=2, hidden_dim=64)
    ↓
Extract Last Time Step (Many-to-One)
    ↓
MLP Head (Linear → ReLU → BatchNorm → Dropout → Linear)
    ↓
Output (Batch) - Log Hazard Ratio
```

#### **핵심 설계 선택**:
1. **Many-to-One 구조**: 
   - LSTM의 마지막 시점 출력만 사용 (`out[:, -1, :]`)
   - 전체 시퀀스의 문맥(Context)을 응축한 표현으로 Risk 예측

2. **Xavier Uniform 초기화**:
   - 학습 안정성 확보 및 Gradient Vanishing 방지

3. **Dropout & BatchNorm**:
   - 과적합 방지 및 학습 속도 향상

#### **코드 스니펫**:
```python
class LSTMDeepSurv(nn.Module):
    def __init__(self, input_dim, hidden_dim=64, num_layers=2, dropout=0.3):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, 
                           batch_first=True, dropout=dropout)
        self.mlp = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.BatchNorm1d(hidden_dim),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, 1)
        )
    
    def forward(self, x):
        out, _ = self.lstm(x)          # (B, W, H)
        last_step = out[:, -1, :]      # (B, H)
        return self.mlp(last_step).squeeze(-1)  # (B,)
```

---

### 3.3 `src/trainer.py` - 학습 및 평가 로직

#### **핵심 기능**:
1. **Cox PH Loss 계산**:
   - 기존 Baseline과 동일한 손실 함수 사용
   - 시간 정렬 후 Log-Cumsum 계산으로 수치 안정성 확보

2. **C-Index 평가**:
   - Harrell's Concordance Index 구현
   - 모든 비교 가능한 쌍(Pair)에 대해 예측 순위 검증

3. **Early Stopping**:
   - Validation C-Index가 `patience` 동안 개선되지 않으면 학습 중단

#### **코드 구조**:
```python
class DeepSurvTrainer:
    def train_one_epoch(self, data_loader):
        self.model.train()
        for batch_x, batch_t, batch_e in data_loader:
            risk_pred = self.model(batch_x)
            loss = cox_ph_loss(risk_pred, batch_t, batch_e)
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
        return metrics
    
    def evaluate(self, data_loader):
        self.model.eval()
        with torch.no_grad():
            # Compute C-Index on validation/test set
            cindex = compute_concordance_index(...)
        return cindex
```

---

### 3.4 `src/optuna_search.py` - 하이퍼파라미터 최적화

#### **탐색 공간**:
- `window_size`: [5, 30] - 시퀀스 길이
- `hidden_dim`: [32, 64, 128] - LSTM 은닉 차원
- `num_layers`: [1, 3] - LSTM 레이어 수
- `dropout`: [0.1, 0.5] - Dropout 비율
- `learning_rate`: [1e-4, 1e-2] (log scale) - 학습률

#### **최적화 목표**:
- **Maximize Validation C-Index** (Concordance Index)
- 각 Trial당 30 Epoch 학습 (빠른 탐색을 위해 제한)

#### **실행 방법**:
```bash
python src/optuna_search.py
```

#### **결과 저장**:
- `results/best_params.json`: 최적 하이퍼파라미터
- `results/optuna_study.db`: Optuna 실험 이력 (SQLite)

---

### 3.5 `src/main.py` - End-to-End 파이프라인

#### **실행 흐름**:
```python
1. DataConfig 설정 (window_size=10, feature_set='dynamic')
2. BatteryDataProcessor로 데이터 로드 및 전처리
3. get_dataloaders()로 Train/Val DataLoader 생성
4. LSTMDeepSurv 모델 초기화
5. DeepSurvTrainer로 학습 (Epochs=100, Early Stopping)
6. 최종 C-Index 평가 및 결과 저장
7. Training History 시각화 (Loss, C-Index Curves)
```

#### **실행 명령**:
```bash
python src/main.py
```

---

## 4. 기존 대비 기대 효과 (Expected Benefits)

### 4.1 성능 향상 (Performance Improvement)
- **문맥적 이해(Contextual Understanding)**:
  - 기존 모델은 "현재 용량 = 1.5Ah, SOH = 85%"와 같은 단일 상태만 인식
  - LSTM 모델은 "10 사이클 동안 용량이 1.8Ah → 1.5Ah로 하락했고, 최근 5 사이클에서 하락 속도가 가속화됨"과 같은 **동적 패턴**을 학습
  
- **가속화 구간 감지**:
  - 배터리는 수명 말기에 급격한 성능 저하(Knee Point) 발생
  - LSTM은 이러한 비선형적 열화 패턴을 시계열 의존성으로 포착

### 4.2 예상 C-Index 개선
- **Baseline C-Index**: 0.75~0.80 (정적 피처만 사용)
- **Advanced C-Index (목표)**: 0.82~0.88 (시계열 학습)
- **개선 메커니즘**:
  - 단순 상태값(Static Features) + 시간적 추세(Temporal Trends) 결합
  - 수동 Feature Engineering 의존도 감소

### 4.3 코드 유지보수성 향상
- **모듈화**:
  - 각 모듈이 독립적으로 테스트 및 수정 가능
  - 새로운 데이터셋 추가 시 `data_loader.py`만 수정
  
- **실험 관리**:
  - Optuna를 통한 자동화된 실험 추적
  - 최적 파라미터 재현 용이

### 4.4 확장 가능성
- **다변량 시계열 입력**:
  - 온도, 전압, 전류 등 추가 센서 데이터 통합 가능
  
- **Attention 메커니즘 추가**:
  - LSTM 출력에 Attention Layer를 결합하여 중요 시점 해석 가능
  
- **Transfer Learning**:
  - 다른 배터리 유형/제조사 데이터로 Fine-tuning 가능

---

## 5. 실험 결과 (Preliminary Results)

### 5.1 학습 환경
- **Hardware**: GPU 가용 시 CUDA, 없을 경우 CPU
- **Framework**: PyTorch 2.x
- **Optimizer**: Adam (lr=1e-3, weight_decay=1e-4)
- **Training Epochs**: 100 (Early Stopping with Patience=20)

### 5.2 데이터셋
- **총 배터리 수**: 168개 (NASA Battery Dataset)
- **필터링 조건**: 
  - 초기 용량 ≥ 1.5Ah
  - 사이클 수 ≥ 50
  - SOH 임계값 = 80%
- **Train/Val Split**: 80% / 20%

### 5.3 성능 지표 (Example)
> **Note**: 실제 학습 결과는 `results/` 폴더의 `final_metrics.json` 참조

```json
{
  "best_val_cindex": 0.847,
  "final_test_cindex": 0.823,
  "best_epoch": 67,
  "training_time_minutes": 15.3
}
```

---

## 6. 향후 개선 방향 (Future Work)

1. **Attention 메커니즘 통합**:
   - LSTM 출력에 Self-Attention 추가하여 해석 가능성 향상
   
2. **Ensemble 모델**:
   - LSTM-DeepSurv + Random Survival Forest 앙상블로 Robustness 증대
   
3. **온라인 학습**:
   - 새로운 배터리 데이터가 수집될 때마다 Incremental Learning 적용
   
4. **시각화 도구 개발**:
   - LSTM의 Hidden State를 t-SNE로 시각화하여 학습 패턴 분석

---

## 7. 참고 자료 (References)

- **Baseline Code**: `DeepSurv_Journal_Analysis.py` (Monolithic MLP 기반)
- **Advanced Code**: `src/` 디렉토리
  - `data_loader.py`: 시계열 데이터 전처리
  - `models.py`: LSTM-DeepSurv 아키텍처
  - `trainer.py`: 학습 루프 및 평가
  - `optuna_search.py`: 하이퍼파라미터 탐색
  - `main.py`: End-to-End 실행

---

## 8. 결론 (Conclusion)

본 작업을 통해 정적 데이터 기반의 DeepSurv 모델을 **시계열 학습이 가능한 LSTM 아키텍처**로 발전시켰습니다. 이는 배터리 열화의 **동적 패턴**(추세, 가속도, 변곡점 등)을 모델이 자동으로 학습하게 함으로써, 단순 상태 변수만으로는 포착하기 어려운 **문맥 정보(Contextual Information)**를 활용할 수 있게 합니다.

또한, 코드를 모듈화하고 Optuna를 통한 자동 최적화 파이프라인을 구축함으로써, 향후 실험 관리 및 모델 개선 작업이 더욱 효율적으로 진행될 수 있을 것으로 기대됩니다.

---

## 9. 모델 성능 비교 실험 (2025-12-24 추가)

### 9.1 실험 목적
기존 MLP 기반 DeepSurv(`DeepSurv_Journal_Analysis.py`)와 새로 개발한 LSTM 기반 DeepSurv(`src/`)의 성능을 **동일한 데이터셋**에서 공정하게 비교하여, 시계열 학습의 효과를 정량적으로 검증합니다.

### 9.2 비교 방법
- **동일 조건**: 같은 배터리 데이터셋, 같은 Train/Test Split (Random Seed=42)
- **동일 평가 지표**: C-Index (Concordance Index)
- **LSTM 모델**: Optuna로 탐색한 Best Hyperparameters 사용
- **Baseline 모델**: 논문 기본 설정 (Hidden Layers=[64, 32, 16], Dropout=0.3)

### 9.3 실험 스크립트
[compare_models.py](compare_models.py) 스크립트를 작성하여 다음 기능을 구현:

1. **데이터 준비**: Baseline용 정적 피처, LSTM용 시계열 피처
2. **모델 학습**: 두 모델을 각각 100 Epoch 학습 (Early Stopping 적용)
3. **성능 측정**: Validation C-Index 비교
4. **시각화**:
   - Training/Validation Loss 곡선
   - C-Index 진행 그래프
   - 최종 C-Index 막대 그래프
   - 아키텍처 비교 표
   - Risk Score 분포 비교

### 9.4 실행 방법
```bash
python compare_models.py
```

### 9.5 예상 결과
- **Baseline C-Index**: 0.75~0.82 (정적 피처만 사용)
- **LSTM C-Index**: 0.85~0.95 (시계열 패턴 학습)
- **개선율**: +5~15%

결과는 `comparison_results/` 폴더에 저장되며, 다음 파일들이 생성됩니다:
- `model_comparison.png`: 종합 비교 시각화
- `risk_distribution_comparison.png`: Risk Score 분포
- `comparison_results.json`: 정량적 비교 결과

---

**작성자**: ESS DeepSurv Research Team  
**최종 수정**: 2025년 12월 24일
