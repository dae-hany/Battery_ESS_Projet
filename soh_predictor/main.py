"""
ë©”ì¸ ì‹¤í–‰ ëª¨ë“ˆ
=============

SOH ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ì˜ ì§„ì…ì 
"""

import random
from pathlib import Path
from typing import Dict, List, Optional

import numpy as np
import pandas as pd

from .config import Config
from .data_loaders import DataLoaderFactory
from .preprocessors import (
    FrequencyHarmonizer,
    FeatureEngineer,
    DomainAdapter,
    SOHEstimator,
    DataAugmenter,
)
from .models import ModelTrainer, SOHPredictor
from .utils import logger, get_rx_columns


class SOHPredictorPipeline:
    """
    SOH ì˜ˆì¸¡ í†µí•© íŒŒì´í”„ë¼ì¸
    
    ì „ì²´ ì›Œí¬í”Œë¡œìš°:
        1. ë°ì´í„° ë¡œë“œ (ë‹¤ì¤‘ ë°ì´í„°ì…‹)
        2. SOH ì¶”ì • ê°œì„ 
        3. ì£¼íŒŒìˆ˜ ì¡°í™”
        4. ë„ë©”ì¸ ì ì‘
        5. ë°ì´í„° ì¦ê°•
        6. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
        7. ëª¨ë¸ í•™ìŠµ (ë‹¤ì¤‘ ì‹œë“œ)
        8. ëª¨ë¸ ì €ì¥
    
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> config = Config()
        >>> pipeline = SOHPredictorPipeline(config)
        >>> results = pipeline.run()
    """
    
    def __init__(self, config: Optional[Config] = None):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            config: ì„¤ì • ê°ì²´. Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        """
        self.config = config or Config()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.data_loader_factory = DataLoaderFactory(self.config)
        self.harmonizer = FrequencyHarmonizer()
        self.feature_engineer = FeatureEngineer(self.config)
        self.domain_adapter = DomainAdapter()
        self.soh_estimator = SOHEstimator(self.config)
        self.augmenter = DataAugmenter(self.config)
        self.trainer = ModelTrainer(self.config)
        
        # ìƒíƒœ
        self.datasets: Dict[str, pd.DataFrame] = {}
        self.combined_df: Optional[pd.DataFrame] = None
        self.predictor: Optional[SOHPredictor] = None
    
    def run(
        self,
        n_seeds: Optional[int] = None,
        grid_search: bool = True,
        save_model: bool = True,
    ) -> Dict[str, Dict]:
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            n_seeds: ì‹¤í—˜ ì‹œë“œ ê°œìˆ˜ (ê¸°ë³¸ê°’: configì—ì„œ ê°€ì ¸ì˜´)
            grid_search: GridSearchCV ì‚¬ìš© ì—¬ë¶€
            save_model: ëª¨ë¸ ì €ì¥ ì—¬ë¶€
        
        Returns:
            ëª¨ë¸ë³„ ì„±ëŠ¥ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        self._print_header()
        
        # 1. ë°ì´í„° ë¡œë“œ
        self.datasets = self._load_data()
        if not self._validate_datasets():
            return {}
        
        # 2. SOH ì¶”ì • ê°œì„ 
        self._improve_soh_estimates()
        
        # 3. ì£¼íŒŒìˆ˜ ì¡°í™” ë° í†µí•©
        self.combined_df = self._harmonize_and_combine()
        if self.combined_df is None or self.combined_df.empty:
            logger.error("âŒ í†µí•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        # 4. í•™ìŠµ ë°ì´í„° ì¤€ë¹„
        train_df = self._prepare_training_data()
        if train_df.empty:
            logger.error("âŒ SOH ë¼ë²¨ì´ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        # 5. ì „ì²˜ë¦¬
        train_df = self._preprocess_data(train_df)
        
        # 6. í”¼ì²˜ ï¿½ï¿½ íƒ€ê²Ÿ ë¶„ë¦¬
        X, y, groups = self._extract_features_and_target(train_df)
        
        # 7. ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜
        n_seeds = n_seeds or self.config.model.n_seeds
        all_results = self._run_multi_seed_experiments(
            X, y, groups, n_seeds, grid_search
        )
        
        # 8. ê²°ê³¼ ì§‘ê³„ ë° ì €ì¥
        aggregated = self._aggregate_results(all_results)
        
        if save_model:
            self._save_model()
        
        # 9. Predictor ìƒì„±
        self.predictor = SOHPredictor(self.trainer)
        
        logger.info("\nâœ… SOH ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ ì™„ë£Œ!")
        return aggregated
    
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """
        ìƒˆ ë°ì´í„°ì— ëŒ€í•œ SOH ì˜ˆì¸¡
        
        Args:
            X: ì…ë ¥ í”¼ì²˜ DataFrame
        
        Returns:
            SOH ì˜ˆì¸¡ê°’ ë°°ì—´
        """
        if self.predictor is None:
            raise RuntimeError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. run()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return self.predictor.predict(X)
    
    def _print_header(self) -> None:
        """í—¤ë” ì¶œë ¥"""
        logger.info("=" * 80)
        logger.info("ğŸš€ ìµœê³ ì˜ SOH ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ")
        logger.info("=" * 80)
        logger.info("\në°ì´í„°ì…‹ í™œìš© ì „ëµ:")
        logger.info("  1. Spectroscopy Individual: ì‹¤ì œ SOH ë¼ë²¨ (ì£¼ í•™ìŠµ ë°ì´í„°)")
        logger.info("  2. Company Battery: ê°œì„ ëœ SOH ì¶”ì • (ë³´ì¡° í•™ìŠµ ë°ì´í„°)")
        logger.info("  3. Li-Ion SoC Estimation: ìƒˆ ë°ì´í„°ì…‹ (pseudo-label)")
        logger.info("=" * 80)
    
    def _load_data(self) -> Dict[str, pd.DataFrame]:
        """ëª¨ë“  ë°ì´í„°ì…‹ ë¡œë“œ"""
        logger.info("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì‹œì‘...")
        return self.data_loader_factory.load_all()
    
    def _validate_datasets(self) -> bool:
        """ë°ì´í„°ì…‹ ìœ íš¨ì„± ê²€ì¦"""
        if 'spectroscopy' not in self.datasets or self.datasets['spectroscopy'].empty:
            logger.error("âŒ Spectroscopy ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ í•™ìŠµ ë¶ˆê°€ëŠ¥.")
            return False
        
        logger.info(f"\nğŸ“Š ë¡œë“œëœ ë°ì´í„°ì…‹: {list(self.datasets.keys())}")
        for name, df in self.datasets.items():
            logger.info(f"  {name}: {len(df)}ê°œ ìƒ˜í”Œ")
        
        return True
    
    def _improve_soh_estimates(self) -> None:
        """ë³´ì¡° ë°ì´í„°ì…‹ì˜ SOH ì¶”ì • ê°œì„ """
        reference_df = self.datasets.get('spectroscopy')
        
        if reference_df is None:
            return
        
        # Company Battery SOH ê°œì„ 
        if 'company_battery' in self.datasets:
            self.datasets['company_battery'] = self.soh_estimator.improve_estimates(
                reference_df, self.datasets['company_battery']
            )
        
        # SoC Estimation SOH ê°œì„ 
        if 'soc_estimation' in self.datasets:
            self.datasets['soc_estimation'] = self.soh_estimator.improve_estimates(
                reference_df, self.datasets['soc_estimation']
            )
    
    def _harmonize_and_combine(self) -> pd.DataFrame:
        """ì£¼íŒŒìˆ˜ ì¡°í™” ë° ë°ì´í„° í†µí•©"""
        dataframes = list(self.datasets.values())
        return self.harmonizer.harmonize(*dataframes)
    
    def _prepare_training_data(self) -> pd.DataFrame:
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„"""
        train_df = self.combined_df[self.combined_df['SOH'].notna()].copy()
        
        logger.info(f"\nğŸ“Š í•™ìŠµ ë°ì´í„°: {len(train_df)}ê°œ ìƒ˜í”Œ")
        
        if 'data_source' in train_df.columns:
            for source in train_df['data_source'].unique():
                count = len(train_df[train_df['data_source'] == source])
                logger.info(f"  {source}: {count}ê°œ")
        
        if 'SOH' in train_df.columns:
            logger.info(f"  SOH ë²”ìœ„: {train_df['SOH'].min():.1f}% ~ {train_df['SOH'].max():.1f}%")
        
        return train_df
    
    def _preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë°ì´í„° ì „ì²˜ë¦¬ (ë„ë©”ì¸ ì ì‘ + ì¦ê°•)"""
        df = self.domain_adapter.adapt(df)
        df = self.augmenter.augment(df, factor=self.config.model.augmentation_factor)
        logger.info(f"\nğŸ“Š ì „ì²˜ë¦¬ í›„ ë°ì´í„°: {len(df)}ê°œ ìƒ˜í”Œ")
        return df
    
    def _extract_features_and_target(
        self, df: pd.DataFrame
    ) -> tuple[pd.DataFrame, pd.Series, Optional[pd.Series]]:
        """í”¼ì²˜, íƒ€ê²Ÿ, ê·¸ë£¹ ì¶”ì¶œ"""
        # í”¼ì²˜ ì»¬ëŸ¼ ì¶”ì¶œ
        r_cols, x_cols = get_rx_columns(df)
        feature_cols = r_cols + x_cols
        X = df[feature_cols]
        
        # ê³ ê¸‰ í”¼ì²˜ ì¶”ì¶œ
        X = self.feature_engineer.extract_features(X)
        logger.info(f"\nğŸ“ˆ í”¼ì²˜ í™•ì¥: {len(feature_cols)}ê°œ â†’ {len(X.columns)}ê°œ")
        
        # íƒ€ê²Ÿ
        y = df['SOH']
        
        # ê·¸ë£¹ (ë°°í„°ë¦¬ ë‹¨ìœ„ ë¶„í• ìš©)
        groups = None
        for col in ['BATTERY_ID', 'battery_id', 'data_source']:
            if col in df.columns:
                groups = df[col].fillna('unknown').astype(str)
                break
        
        return X, y, groups
    
    def _run_multi_seed_experiments(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        groups: Optional[pd.Series],
        n_seeds: int,
        grid_search: bool,
    ) -> List[Dict]:
        """ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ì‹¤í–‰"""
        # ì‹œë“œ ìƒì„±
        if grid_search:
            seeds = [random.randint(0, 2**31 - 1) for _ in range(n_seeds)]
            logger.info(f"\nğŸ¯ ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜: {seeds}")
        else:
            seeds = [self.config.model.random_state]
        
        all_results = []
        for idx, seed in enumerate(seeds, 1):
            logger.info("\n" + "=" * 60)
            logger.info(f"  Seed {idx}/{len(seeds)}: random_state={seed}")
            logger.info("=" * 60)
            
            results = self.trainer.train(
                X, y,
                groups=groups,
                use_cv=True,
                grid_search=grid_search,
                random_state=seed,
            )
            all_results.append(results)
        
        return all_results
    
    def _aggregate_results(self, all_results: List[Dict]) -> Dict[str, Dict]:
        """ë‹¤ì¤‘ ì‹œë“œ ê²°ê³¼ ì§‘ê³„"""
        if not all_results:
            return {}
        
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ê²°ê³¼ ì§‘ê³„")
        logger.info("=" * 60)
        
        aggregated = {}
        model_names = all_results[0].keys()
        
        for model_name in model_names:
            mae_values = [r[model_name]['mae_mean'] for r in all_results]
            r2_values = [r[model_name]['r2_mean'] for r in all_results]
            
            aggregated[model_name] = {
                'mae_mean': np.mean(mae_values),
                'mae_std': np.std(mae_values),
                'r2_mean': np.mean(r2_values),
                'r2_std': np.std(r2_values),
            }
            
            logger.info(f"\n{model_name}:")
            logger.info(f"  MAE: {aggregated[model_name]['mae_mean']:.4f}% (Â±{aggregated[model_name]['mae_std']:.4f}%)")
            logger.info(f"  RÂ²: {aggregated[model_name]['r2_mean']:.4f} (Â±{aggregated[model_name]['r2_std']:.4f})")
        
        return aggregated
    
    def _save_model(self) -> None:
        """ëª¨ë¸ ì €ì¥"""
        output_dir = self.config.paths.model_output_dir
        output_dir.mkdir(parents=True, exist_ok=True)
        
        filepath = output_dir / "ultimate_soh_model.pkl"
        self.trainer.save(filepath)
        logger.info(f"\nâœ… ëª¨ë¸ ì €ì¥: {filepath}")


def main():
    """CLI ì§„ì…ì """
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ë°°í„°ë¦¬ SOH ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ê¸°ë³¸ ì‹¤í–‰ (GridSearch + 5 ì‹œë“œ)
  python -m soh_predictor
  
  # ë¹ ë¥¸ ì‹¤í–‰ (GridSearch ì—†ì´)
  python -m soh_predictor --fast
  
  # ì‹œë“œ ê°œìˆ˜ ì§€ì •
  python -m soh_predictor --n-seeds 10
  
  # ì»¤ìŠ¤í…€ ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬
  python -m soh_predictor --base-dir /path/to/data
        """
    )
    
    parser.add_argument(
        "--base-dir",
        type=Path,
        default=Path("."),
        help="ë°ì´í„°ì…‹ ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: í˜„ì¬ ë””ë ‰í† ë¦¬)",
    )
    parser.add_argument(
        "--n-seeds",
        type=int,
        default=5,
        help="ì‹¤í—˜ ì‹œë“œ ê°œìˆ˜ (ê¸°ë³¸: 5)",
    )
    parser.add_argument(
        "--fast",
        action="store_true",
        help="ë¹ ë¥¸ ì‹¤í–‰ (GridSearch ë¹„í™œì„±í™”)",
    )
    parser.add_argument(
        "--no-save",
        action="store_true",
        help="ëª¨ë¸ ì €ì¥ ë¹„í™œì„±í™”",
    )
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="ìƒì„¸ ë¡œê¹…",
    )
    
    args = parser.parse_args()
    
    # ë¡œê¹… ë ˆë²¨ ì„¤ì •
    if args.verbose:
        import logging
        logging.getLogger().setLevel(logging.DEBUG)
    
    # ì„¤ì • ìƒì„±
    from .config import PathConfig
    config = Config(paths=PathConfig(base_dir=args.base_dir))
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = SOHPredictorPipeline(config)
    results = pipeline.run(
        n_seeds=args.n_seeds if not args.fast else 1,
        grid_search=not args.fast,
        save_model=not args.no_save,
    )
    
    return results


if __name__ == "__main__":
    main()