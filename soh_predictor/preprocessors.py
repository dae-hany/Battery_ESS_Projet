"""
ì „ì²˜ë¦¬ ëª¨ë“ˆ
==========
ë°ì´í„° ì •ì œ, í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§, ë„ë©”ì¸ ì ì‘
"""

from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor

from .config import Config
from .utils import (
    logger, extract_frequency_from_column, get_rx_columns,
    normalize_frequency_column_name, safe_divide
)


class FrequencyHarmonizer:
    """ì£¼íŒŒìˆ˜ ì»¬ëŸ¼ ì¡°í™” (ë°ì´í„°ì…‹ ê°„ í‘œì¤€í™”)"""
    
    def harmonize(self, *dataframes: pd.DataFrame) -> pd.DataFrame:
        """ëª¨ë“  ë°ì´í„°í”„ë ˆì„ì˜ ì£¼íŒŒìˆ˜ ì»¬ëŸ¼ í†µì¼"""
        logger.info("ğŸ”§ ì£¼íŒŒìˆ˜ ì»¬ëŸ¼ ì¡°í™” ì¤‘...")
        
        # ì£¼íŒŒìˆ˜-ì»¬ëŸ¼ ë§¤í•‘ ìˆ˜ì§‘
        freq_mapping = self._collect_frequency_mapping(dataframes)
        
        if not freq_mapping:
            return pd.DataFrame()
        
        common_freqs = sorted(freq_mapping.keys())
        logger.info(f"  ë°œê²¬ëœ ì£¼íŒŒìˆ˜: {len(common_freqs)}ê°œ")
        
        # ê° ë°ì´í„°í”„ë ˆì„ ë³€í™˜
        harmonized_dfs = [
            self._transform_dataframe(df, freq_mapping, common_freqs)
            for df in dataframes if not df.empty
        ]
        
        if not harmonized_dfs:
            return pd.DataFrame()
        
        combined = pd.concat(harmonized_dfs, ignore_index=True)
        logger.info(f"  âœ… ì¡°í™” ì™„ë£Œ: {len(combined)}ê°œ ìƒ˜í”Œ")
        return combined
    
    def _collect_frequency_mapping(
        self, dataframes: Tuple[pd.DataFrame, ...]
    ) -> Dict[float, Dict[int, Tuple[str, Optional[str]]]]:
        """ì£¼íŒŒìˆ˜ë³„ ì»¬ëŸ¼ ë§¤í•‘ ìˆ˜ì§‘"""
        freq_map: Dict[float, Dict[int, Tuple[str, Optional[str]]]] = {}
        
        for df_idx, df in enumerate(dataframes):
            if df.empty:
                continue
            
            r_cols, _ = get_rx_columns(df)
            for r_col in r_cols:
                freq = extract_frequency_from_column(r_col)
                if freq is None:
                    continue
                
                # ì •ê·œí™”
                norm_freq = 1000 if freq >= 1000 else int(freq) if freq == int(freq) else freq
                
                if norm_freq not in freq_map:
                    freq_map[norm_freq] = {}
                
                x_col = r_col.replace('R_', 'X_')
                x_col = x_col if x_col in df.columns else None
                freq_map[norm_freq][df_idx] = (r_col, x_col)
        
        return freq_map
    
    def _transform_dataframe(
        self, 
        df: pd.DataFrame, 
        freq_mapping: Dict,
        common_freqs: List[float]
    ) -> pd.DataFrame:
        """ë‹¨ì¼ ë°ì´í„°í”„ë ˆì„ì„ ê³µí†µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        harmonized = pd.DataFrame()
        
        # ë©”íƒ€ ì»¬ëŸ¼ ë³µì‚¬
        for col in ['SOH', 'data_source', 'condition', 'BATTERY_ID', 'battery_id', 'soh_estimated']:
            if col in df.columns:
                harmonized[col] = df[col].values
        
        # ì£¼íŒŒìˆ˜ ì»¬ëŸ¼ ë§¤í•‘
        df_idx = None
        for freq in common_freqs:
            if freq in freq_mapping:
                for idx in freq_mapping[freq]:
                    if idx not in [None]:  # df ì¸ë±ìŠ¤ ì°¾ê¸°
                        df_idx = idx
                        break
        
        for freq in common_freqs:
            target_r = f'R_{normalize_frequency_column_name(freq)}'
            target_x = f'X_{normalize_frequency_column_name(freq)}'
            
            # ì›ë³¸ì—ì„œ ë§¤ì¹­ë˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸°
            source_cols = self._find_source_columns(df, freq)
            
            if source_cols:
                harmonized[target_r] = df[source_cols[0]].values
                harmonized[target_x] = df[source_cols[1]].values if source_cols[1] else 0
            else:
                harmonized[target_r] = 0
                harmonized[target_x] = 0
        
        return harmonized
    
    def _find_source_columns(
        self, df: pd.DataFrame, target_freq: float
    ) -> Optional[Tuple[str, Optional[str]]]:
        """ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì—ì„œ í•´ë‹¹ ì£¼íŒŒìˆ˜ ì»¬ëŸ¼ ì°¾ê¸°"""
        r_cols, _ = get_rx_columns(df)
        
        for r_col in r_cols:
            freq = extract_frequency_from_column(r_col)
            if freq is None:
                continue
            
            norm_freq = 1000 if freq >= 1000 else int(freq) if freq == int(freq) else freq
            if norm_freq == target_freq:
                x_col = r_col.replace('R_', 'X_')
                return (r_col, x_col if x_col in df.columns else None)
        
        return None


class FeatureEngineer:
    """í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"""
    
    def __init__(self, config: Config):
        self.config = config
        self.freq_weights = config.frequency.weights
        self.key_freqs = config.frequency.key_frequencies
    
    def extract_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê³ ê¸‰ í”¼ì²˜ ì¶”ì¶œ"""
        enhanced = df.copy()
        r_cols, x_cols = get_rx_columns(df)
        
        if not r_cols:
            return enhanced
        
        # ê¸°ë³¸ í†µê³„
        enhanced = self._add_basic_stats(enhanced, r_cols, x_cols)
        
        # ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ í†µê³„
        enhanced = self._add_frequency_band_stats(enhanced, r_cols)
        
        # í•µì‹¬ ì£¼íŒŒìˆ˜ íŠ¹ì„±
        enhanced = self._add_key_frequency_features(enhanced, df)
        
        # ë¹„ìœ¨ í”¼ì²˜
        enhanced = self._add_ratio_features(enhanced)
        
        return enhanced
    
    def _add_basic_stats(
        self, df: pd.DataFrame, r_cols: List[str], x_cols: List[str]
    ) -> pd.DataFrame:
        """ê¸°ë³¸ í†µê³„ í”¼ì²˜ ì¶”ê°€"""
        df['R_mean'] = df[r_cols].mean(axis=1)
        df['R_std'] = df[r_cols].std(axis=1)
        df['R_min'] = df[r_cols].min(axis=1)
        df['R_max'] = df[r_cols].max(axis=1)
        df['R_range'] = df['R_max'] - df['R_min']
        
        if x_cols:
            df['X_mean'] = df[x_cols].mean(axis=1)
            df['X_std'] = df[x_cols].std(axis=1)
            df['X_min'] = df[x_cols].min(axis=1)
            df['X_max'] = df[x_cols].max(axis=1)
            df['X_range'] = df['X_max'] - df['X_min']
        
        return df
    
    def _add_frequency_band_stats(
        self, df: pd.DataFrame, r_cols: List[str]
    ) -> pd.DataFrame:
        """ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ í†µê³„ ì¶”ê°€"""
        bands = {
            'low': (0, 10),
            'mid': (10, 100),
            'high': (100, float('inf')),
        }
        
        for band_name, (low, high) in bands.items():
            band_cols = [
                col for col in r_cols
                if (freq := extract_frequency_from_column(col)) 
                and low < freq <= high
            ]
            
            if band_cols:
                df[f'{band_name}_freq_R_mean'] = df[band_cols].mean(axis=1)
                df[f'{band_name}_freq_R_std'] = df[band_cols].std(axis=1)
        
        return df
    
    def _add_key_frequency_features(
        self, df: pd.DataFrame, original_df: pd.DataFrame
    ) -> pd.DataFrame:
        """í•µì‹¬ ì£¼íŒŒìˆ˜ ê°€ì¤‘ í”¼ì²˜ ì¶”ê°€"""
        for freq_str in self.key_freqs:
            r_col = f"R_{freq_str}"
            x_col = f"X_{freq_str}"
            
            if r_col not in original_df.columns or x_col not in original_df.columns:
                continue
            
            weight = self.freq_weights.get(freq_str, 1.0)
            
            df[f'R_{freq_str}_weighted'] = original_df[r_col] * weight
            df[f'X_{freq_str}_weighted'] = original_df[x_col] * weight
            
            # ì„í”¼ë˜ìŠ¤ í¬ê¸° ë° ìœ„ìƒê°
            df[f'Z_{freq_str}'] = np.sqrt(
                original_df[r_col]**2 + original_df[x_col]**2
            )
            df[f'Phase_{freq_str}'] = np.arctan2(
                original_df[x_col], original_df[r_col]
            )
        
        return df
    
    def _add_ratio_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë¹„ìœ¨ í”¼ì²˜ ì¶”ê°€"""
        if 'high_freq_R_mean' in df.columns and 'low_freq_R_mean' in df.columns:
            df['high_low_freq_ratio'] = safe_divide(
                df['high_freq_R_mean'].values,
                np.abs(df['low_freq_R_mean'].values)
            )
        return df


class DomainAdapter:
    """ë„ë©”ì¸ ì ì‘: ë°ì´í„°ì…‹ ê°„ ë¶„í¬ ì°¨ì´ í•´ê²°"""
    
    def __init__(self, reference_source: str = 'spectroscopy'):
        self.reference_source = reference_source
    
    def adapt(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë„ë©”ì¸ ì ì‘ ì ìš©"""
        logger.info("ğŸŒ ë„ë©”ì¸ ì ì‘ ì ìš© ì¤‘...")
        
        if 'data_source' not in df.columns:
            logger.warning("data_source ì»¬ëŸ¼ ì—†ìŒ, ìŠ¤í‚µ")
            return df
        
        sources = df['data_source'].unique()
        if len(sources) < 2:
            logger.warning("ë°ì´í„° ì†ŒìŠ¤ 1ê°œ ì´í•˜, ìŠ¤í‚µ")
            return df
        
        # ì†ŒìŠ¤ë³„ í†µê³„ ê³„ì‚°
        source_stats = self._compute_source_stats(df)
        
        if self.reference_source not in source_stats:
            self.reference_source = list(source_stats.keys())[0]
        
        ref_stats = source_stats[self.reference_source]
        logger.info(f"  ê¸°ì¤€: {self.reference_source}")
        
        # ì ì‘ ì ìš©
        adapted_df = df.copy()
        r_cols, x_cols = get_rx_columns(df)
        
        for source, stats in source_stats.items():
            if source == self.reference_source:
                continue
            
            mask = adapted_df['data_source'] == source
            if stats['std'] > 0:
                for col in r_cols + x_cols:
                    if col in adapted_df.columns:
                        adapted_df.loc[mask, col] = (
                            (adapted_df.loc[mask, col] - stats['mean']) 
                            / stats['std'] * ref_stats['std'] + ref_stats['mean']
                        )
        
        logger.info("  âœ… ë„ë©”ì¸ ì ì‘ ì™„ë£Œ")
        return adapted_df
    
    def _compute_source_stats(self, df: pd.DataFrame) -> Dict[str, Dict[str, float]]:
        """ì†ŒìŠ¤ë³„ í†µê³„ ê³„ì‚°"""
        stats = {}
        r_cols, _ = get_rx_columns(df)
        
        for source in df['data_source'].unique():
            source_data = df[df['data_source'] == source]
            if r_cols:
                stats[source] = {
                    'mean': source_data[r_cols].mean().mean(),
                    'std': source_data[r_cols].mean().std(),
                }
        return stats


class SOHEstimator:
    """SOH ì¶”ì • ê°œì„ ê¸°"""
    
    def __init__(self, config: Config):
        self.config = config
        self.blend_ratio = config.soh_estimation.estimation_blend_ratio
    
    def improve_estimates(
        self, 
        reference_df: pd.DataFrame, 
        target_df: pd.DataFrame
    ) -> pd.DataFrame:
        """ì°¸ì¡° ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ íƒ€ê²Ÿì˜ SOH ì¶”ì • ê°œì„ """
        logger.info("ğŸ”§ SOH ì¶”ì • ê°œì„  ì¤‘...")
        
        if reference_df.empty or target_df.empty:
            return target_df
        
        # ê³µí†µ í”¼ì²˜ ì°¾ê¸°
        common_cols = self._find_common_features(reference_df, target_df)
        
        if len(common_cols) < 4:
            logger.warning("ê³µí†µ í”¼ì²˜ ë¶€ì¡±, ì´ˆê¸° ì¶”ì •ê°’ ì‚¬ìš©")
            return target_df
        
        # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
        model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)
        
        X_ref = reference_df[common_cols].fillna(0)
        y_ref = reference_df['SOH']
        model.fit(X_ref, y_ref)
        
        X_target = target_df[common_cols].fillna(0)
        predicted_soh = model.predict(X_target)
        
        # ë¸”ë Œë”©
        target_df = target_df.copy()
        original_soh = target_df['SOH'].values
        target_df['SOH'] = self.blend_ratio * predicted_soh + (1 - self.blend_ratio) * original_soh
        
        logger.info(f"  âœ… ì¡°ì • ë²”ìœ„: {target_df['SOH'].min():.1f}% ~ {target_df['SOH'].max():.1f}%")
        return target_df
    
    def _find_common_features(
        self, df1: pd.DataFrame, df2: pd.DataFrame
    ) -> List[str]:
        """ê³µí†µ R/X í”¼ì²˜ ì°¾ê¸°"""
        r_cols1, x_cols1 = get_rx_columns(df1)
        r_cols2, x_cols2 = get_rx_columns(df2)
        
        common = set(r_cols1 + x_cols1) & set(r_cols2 + x_cols2)
        return sorted(list(common))


class DataAugmenter:
    """ë°ì´í„° ì¦ê°•"""
    
    def __init__(self, config: Config):
        self.config = config
        self.noise_factor = config.model.noise_factor
    
    def augment(
        self, df: pd.DataFrame, factor: float = 2.0
    ) -> pd.DataFrame:
        """ë°ì´í„° ì¦ê°• ìˆ˜í–‰"""
        logger.info(f"ğŸ“ˆ ë°ì´í„° ì¦ê°• ì¤‘ (ëª©í‘œ: {factor}ë°°)...")
        
        original_size = len(df)
        target_size = int(original_size * factor)
        needed = target_size - original_size
        
        if needed <= 0:
            return df
        
        r_cols, x_cols = get_rx_columns(df)
        if not r_cols:
            return df
        
        augmented_rows = []
        np.random.seed(self.config.model.random_state)
        
        # ë…¸ì´ì¦ˆ ì¶”ê°€
        augmented_rows.extend(
            self._add_noise_samples(df, r_cols + x_cols, min(needed, original_size))
        )
        
        # ë³´ê°„
        remaining = needed - len(augmented_rows)
        if remaining > 0 and 'SOH' in df.columns:
            augmented_rows.extend(
                self._interpolate_samples(df, r_cols + x_cols, remaining)
            )
        
        if augmented_rows:
            augmented_df = pd.DataFrame(augmented_rows)
            combined = pd.concat([df, augmented_df], ignore_index=True)
            logger.info(f"  âœ… {original_size}ê°œ â†’ {len(combined)}ê°œ")
            return combined
        
        return df
    
    def _add_noise_samples(
        self, df: pd.DataFrame, cols: List[str], n_samples: int
    ) -> List[pd.Series]:
        """ë…¸ì´ì¦ˆ ì¶”ê°€ ìƒ˜í”Œ ìƒì„±"""
        samples = []
        for _ in range(n_samples):
            idx = np.random.randint(0, len(df))
            row = df.iloc[idx].copy()
            
            for col in cols:
                if col in row and pd.notna(row[col]):
                    noise = np.random.normal(0, abs(row[col]) * self.noise_factor)
                    row[col] = row[col] + noise
            
            samples.append(row)
        return samples
    
    def _interpolate_samples(
        self, df: pd.DataFrame, cols: List[str], n_samples: int
    ) -> List[pd.Series]:
        """ë³´ê°„ ìƒ˜í”Œ ìƒì„±"""
        samples = []
        soh_range = (df['SOH'].min(), df['SOH'].max())
        soh_values = np.linspace(soh_range[0], soh_range[1], min(n_samples, 20))
        
        for target_soh in soh_values:
            distances = np.abs(df['SOH'].values - target_soh)
            closest = np.argsort(distances)[:2]
            
            if len(closest) >= 2:
                row1, row2 = df.iloc[closest[0]], df.iloc[closest[1]]
                w1 = 1 / (distances[closest[0]] + 1e-6)
                w2 = 1 / (distances[closest[1]] + 1e-6)
                w_sum = w1 + w2
                
                new_row = row1.copy()
                for col in cols:
                    if col in row1 and col in row2:
                        new_row[col] = (w1 * row1[col] + w2 * row2[col]) / w_sum
                new_row['SOH'] = target_soh
                samples.append(new_row)
        
        return samples