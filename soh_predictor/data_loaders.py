"""
ë°ì´í„° ë¡œë” ëª¨ë“ˆ
===============
ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë°°í„°ë¦¬ EIS ë°ì´í„° ë¡œë“œ
"""

from abc import ABC, abstractmethod
from pathlib import Path
from typing import Dict, List, Optional

import pandas as pd
import numpy as np

from .config import Config, SOHEstimationConfig
from .utils import (
    logger, normalize_string, extract_soh_from_filename,
    extract_battery_id, parse_complex_impedance, get_rx_columns,
    normalize_frequency_column_name
)


class BaseDataLoader(ABC):
    """ë°ì´í„° ë¡œë” ë² ì´ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, config: Config):
        self.config = config
    
    @abstractmethod
    def load(self, data_dir: Path) -> pd.DataFrame:
        """ë°ì´í„° ë¡œë“œ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        pass
    
    def _to_numeric_columns(self, df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:
        """ì»¬ëŸ¼ë“¤ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜"""
        df = df.copy()
        for col in columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        return df
    
    def _log_load_result(self, name: str, df: pd.DataFrame) -> None:
        """ë¡œë“œ ê²°ê³¼ ë¡œê¹…"""
        if df.empty:
            logger.warning(f"{name}: ë°ì´í„° ì—†ìŒ")
        else:
            logger.info(f"{name}: {len(df)}ê°œ ìƒ˜í”Œ ë¡œë“œ ì™„ë£Œ")
            if 'SOH' in df.columns:
                logger.info(f"  SOH ë²”ìœ„: {df['SOH'].min():.1f}% ~ {df['SOH'].max():.1f}%")


class SpectroscopyLoader(BaseDataLoader):
    """Spectroscopy Individual ë°ì´í„° ë¡œë” (ì‹¤ì œ SOH ë¼ë²¨)"""
    
    def load(self, data_dir: Path) -> pd.DataFrame:
        logger.info("ğŸ“Š Spectroscopy ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        if not data_dir.exists():
            logger.warning(f"ê²½ë¡œ ì—†ìŒ: {data_dir}")
            return pd.DataFrame()
        
        csv_files = list(data_dir.glob("*.csv"))
        logger.info(f"  íŒŒì¼ ìˆ˜: {len(csv_files)}ê°œ")
        
        records = []
        for file_path in csv_files:
            record = self._process_file(file_path)
            if record is not None:
                records.append(record)
        
        df = pd.DataFrame(records) if records else pd.DataFrame()
        self._log_load_result("Spectroscopy", df)
        return df
    
    def _process_file(self, file_path: Path) -> Optional[Dict]:
        """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬"""
        try:
            soh = extract_soh_from_filename(file_path.name)
            if soh is None:
                return None
            
            df = pd.read_csv(file_path)
            r_cols, x_cols = get_rx_columns(df)
            df = self._to_numeric_columns(df, r_cols + x_cols)
            
            valid_df = df[r_cols + x_cols].dropna(how='all')
            if valid_df.empty:
                return None
            
            record = valid_df.mean().to_dict()
            record.update({
                'SOH': soh,
                'data_source': 'spectroscopy',
                'battery_id': extract_battery_id(file_path.name),
            })
            return record
            
        except Exception as e:
            logger.warning(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {file_path.name} - {e}")
            return None


class CompanyBatteryLoader(BaseDataLoader):
    """Company Battery ë°ì´í„° ë¡œë”"""
    
    def load(self, data_dir: Path) -> pd.DataFrame:
        logger.info("ğŸ“Š Company Battery ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        if not data_dir.exists():
            logger.warning(f"ê²½ë¡œ ì—†ìŒ: {data_dir}")
            return pd.DataFrame()
        
        csv_files = list(data_dir.glob("*.csv"))
        logger.info(f"  íŒŒì¼ ìˆ˜: {len(csv_files)}ê°œ")
        
        records = []
        for file_path in csv_files:
            record = self._process_file(file_path)
            if record is not None:
                records.append(record)
        
        df = pd.DataFrame(records) if records else pd.DataFrame()
        self._log_load_result("Company Battery", df)
        
        if not df.empty:
            self._log_condition_counts(df)
        
        return df
    
    def _process_file(self, file_path: Path) -> Optional[Dict]:
        """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬"""
        try:
            condition = self._find_condition(file_path.name)
            if condition is None:
                return None
            
            df = pd.read_csv(file_path, skipinitialspace=True)
            df.columns = df.columns.str.strip()
            
            r_cols, x_cols = get_rx_columns(df)
            df = self._to_numeric_columns(df, r_cols + x_cols)
            
            valid_df = df[r_cols + x_cols].dropna(how='all')
            if valid_df.empty:
                return None
            
            soh_map = self.config.soh_estimation.condition_soh_map
            record = valid_df.mean().to_dict()
            record.update({
                'SOH': soh_map[condition],
                'data_source': 'company_battery',
                'condition': condition,
                'soh_estimated': True,
            })
            return record
            
        except Exception as e:
            logger.warning(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {file_path.name} - {e}")
            return None
    
    def _find_condition(self, filename: str) -> Optional[str]:
        """íŒŒì¼ëª…ì—ì„œ ë°°í„°ë¦¬ ìƒíƒœ ì¶”ì¶œ"""
        filename_norm = normalize_string(filename)
        soh_map = self.config.soh_estimation.condition_soh_map
        
        for key in soh_map:
            if normalize_string(key) in filename_norm:
                return key
        
        # ì˜ë¬¸ ë§¤ì¹­
        filename_lower = filename.lower()
        if 'new' in filename_lower:
            return 'ì‹ í’ˆ'
        if 'bad' in filename_lower or 'defect' in filename_lower:
            return 'ë¶ˆëŸ‰'
        
        return None
    
    def _log_condition_counts(self, df: pd.DataFrame) -> None:
        """ìƒíƒœë³„ ê°œìˆ˜ ë¡œê¹…"""
        for condition in df['condition'].unique():
            count = len(df[df['condition'] == condition])
            logger.info(f"  {condition}: {count}ê°œ")


class MendeleyFormatLoader(BaseDataLoader):
    """Mendeley í˜•ì‹ ë°ì´í„° ë¡œë” (mbv3bx847g, Samsung ë“±)"""
    
    def __init__(self, config: Config, source_name: str, pseudo_soh: float = 95.0):
        super().__init__(config)
        self.source_name = source_name
        self.pseudo_soh = pseudo_soh
    
    def load(self, data_dir: Path) -> pd.DataFrame:
        logger.info(f"ğŸ“Š {self.source_name} ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        freq_file = data_dir / "frequencies.csv"
        imp_file = data_dir / "impedance.csv"
        
        # ëŒ€ë¬¸ì íŒŒì¼ëª…ë„ ì²´í¬
        if not freq_file.exists():
            freq_file = data_dir / "FREQUENCIES.CSV"
        if not imp_file.exists():
            imp_file = data_dir / "IMPEDANCE.CSV"
        
        if not (freq_file.exists() and imp_file.exists()):
            logger.warning(f"íŒŒì¼ ì—†ìŒ: {data_dir}")
            return pd.DataFrame()
        
        try:
            freq_df = pd.read_csv(freq_file)
            imp_df = pd.read_csv(imp_file)
            
            # ë³µì†Œìˆ˜ íŒŒì‹±
            imp_df[['R', 'X']] = imp_df['IMPEDANCE_VALUE'].apply(
                lambda x: pd.Series(parse_complex_impedance(x))
            )
            
            imp_df = imp_df.merge(freq_df, on='FREQUENCY_ID', how='left')
            
            # í”¼ë²—
            pivoted_data = self._pivot_data(imp_df)
            
            df = pd.DataFrame(pivoted_data)
            df['data_source'] = self.source_name
            df['SOH'] = self.pseudo_soh
            
            self._log_load_result(self.source_name, df)
            return df
            
        except Exception as e:
            logger.error(f"ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def _pivot_data(self, imp_df: pd.DataFrame) -> List[Dict]:
        """ì¸¡ì • ë‹¨ìœ„ë¡œ í”¼ë²—"""
        pivoted = []
        group_cols = ['MEASURE_ID', 'SOC', 'BATTERY_ID']
        available_cols = [c for c in group_cols if c in imp_df.columns]
        
        for keys, group in imp_df.groupby(available_cols):
            row = dict(zip(available_cols, keys if isinstance(keys, tuple) else [keys]))
            
            for _, freq_row in group.iterrows():
                freq_val = freq_row.get('FREQUENCY_VALUE')
                if pd.isna(freq_val):
                    continue
                
                freq_str = normalize_frequency_column_name(freq_val)
                row[f'R_{freq_str}'] = freq_row['R']
                row[f'X_{freq_str}'] = freq_row['X']
            
            pivoted.append(row)
        
        return pivoted


class SoCEstimationLoader(BaseDataLoader):
    """Li-Ion SoC Estimation ë°ì´í„° ë¡œë”"""
    
    def __init__(self, config: Config, pseudo_soh: float = 95.0):
        super().__init__(config)
        self.pseudo_soh = pseudo_soh
    
    def load(self, data_dir: Path) -> pd.DataFrame:
        logger.info("ğŸ“Š Li-Ion SoC Estimation ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        if not data_dir.exists():
            logger.warning(f"ë””ë ‰í† ë¦¬ ì—†ìŒ: {data_dir}")
            return pd.DataFrame()
        
        battery_dirs = sorted([
            d for d in data_dir.iterdir() 
            if d.is_dir() and d.name.startswith('B')
        ])
        
        if not battery_dirs:
            logger.warning("ë°°í„°ë¦¬ ë””ë ‰í† ë¦¬ ì—†ìŒ (B01~B11 ê¸°ëŒ€)")
            return pd.DataFrame()
        
        all_records = []
        for battery_dir in battery_dirs:
            records = self._process_battery_dir(battery_dir)
            all_records.extend(records)
        
        if not all_records:
            return pd.DataFrame()
        
        df = pd.DataFrame(all_records)
        df['data_source'] = 'soc_estimation'
        df['SOH'] = self.pseudo_soh
        
        self._log_load_result("Li-Ion SoC Estimation", df)
        return df
    
    def _process_battery_dir(self, battery_dir: Path) -> List[Dict]:
        """ë°°í„°ë¦¬ ë””ë ‰í† ë¦¬ ì²˜ë¦¬"""
        battery_id = battery_dir.name
        eis_base = battery_dir / 'EIS measurements'
        
        if not eis_base.exists():
            return []
        
        # CSV íŒŒì¼ ìˆ˜ì§‘
        csv_files = []
        for test_dir in eis_base.iterdir():
            if test_dir.is_dir() and test_dir.name.startswith('Test'):
                hioki_dir = test_dir / 'Hioki'
                if hioki_dir.exists():
                    csv_files.extend(hioki_dir.glob('*.csv'))
        
        if not csv_files:
            return []
        
        logger.info(f"  ì²˜ë¦¬ ì¤‘: {battery_id} ({len(csv_files)} íŒŒì¼)")
        
        records = []
        for csv_file in csv_files:
            record = self._process_csv(csv_file, battery_id)
            if record:
                records.append(record)
        
        return records
    
    def _process_csv(self, csv_file: Path, battery_id: str) -> Optional[Dict]:
        """ë‹¨ì¼ CSV ì²˜ë¦¬"""
        try:
            df = pd.read_csv(csv_file)
            
            # ì»¬ëŸ¼ ì°¾ê¸°
            freq_col = self._find_column(df, ['Frequency(Hz)', 'frequency', 'freq'])
            r_col = self._find_column(df, ['R(ohm)', 'R', 'real'])
            x_col = self._find_column(df, ['X(ohm)', 'X', 'imag'])
            
            if not all([freq_col, r_col, x_col]):
                return None
            
            # SOC ì¶”ì¶œ
            soc = self._extract_soc_from_filename(csv_file.name)
            
            # í”¼ë²—
            row = {
                'BATTERY_ID': battery_id,
                'MEASURE_ID': csv_file.stem,
                'SOC': soc,
            }
            
            for _, freq_row in df.iterrows():
                freq_val = freq_row[freq_col]
                if pd.isna(freq_val):
                    continue
                
                freq_str = normalize_frequency_column_name(freq_val)
                row[f'R_{freq_str}'] = freq_row[r_col]
                row[f'X_{freq_str}'] = freq_row[x_col]
            
            return row
            
        except Exception as e:
            logger.warning(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {csv_file.name} - {e}")
            return None
    
    def _find_column(self, df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
        """í›„ë³´ ì¤‘ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸°"""
        for col in df.columns:
            col_lower = col.lower()
            for candidate in candidates:
                if candidate.lower() in col_lower:
                    return col
        return None
    
    def _extract_soc_from_filename(self, filename: str) -> Optional[float]:
        """íŒŒì¼ëª…ì—ì„œ SOC ì¶”ì¶œ (ì˜ˆ: Hk_IFR14500_SoC_100_...)"""
        parts = filename.split('_')
        for i, part in enumerate(parts):
            if part.lower() == 'soc' and i + 1 < len(parts):
                try:
                    return float(parts[i + 1])
                except ValueError:
                    pass
        return None


class DataLoaderFactory:
    """ë°ì´í„° ë¡œë” íŒ©í† ë¦¬"""
    
    def __init__(self, config: Config):
        self.config = config
    
    def load_all(self) -> Dict[str, pd.DataFrame]:
        """ëª¨ë“  ë°ì´í„°ì…‹ ë¡œë“œ"""
        paths = self.config.paths
        
        datasets = {
            'spectroscopy': SpectroscopyLoader(self.config).load(paths.spectroscopy_dir),
            'company_battery': CompanyBatteryLoader(self.config).load(paths.company_battery_dir),
        }
        
        # ì„ íƒì  ë°ì´í„°ì…‹
        if paths.samsung_dir.exists():
            datasets['samsung'] = MendeleyFormatLoader(
                self.config, 'samsung_icr18650'
            ).load(paths.samsung_dir)
        
        if paths.soc_estimation_dir.exists():
            datasets['soc_estimation'] = SoCEstimationLoader(
                self.config
            ).load(paths.soc_estimation_dir)
        
        return {k: v for k, v in datasets.items() if not v.empty}